# LiteLLM Proxy Configuration
# See: https://docs.litellm.ai/docs/proxy/configs

model_list:
  # Claude models via Anthropic API
  - model_name: claude-opus
    litellm_params:
      model: anthropic/claude-3-opus-20240229
      api_key: os.environ/ANTHROPIC_API_KEY

  - model_name: claude-sonnet
    litellm_params:
      model: anthropic/claude-3-5-sonnet-20241022
      api_key: os.environ/ANTHROPIC_API_KEY

  - model_name: claude-haiku
    litellm_params:
      model: anthropic/claude-3-5-haiku-20241022
      api_key: os.environ/ANTHROPIC_API_KEY

  # GPT models via OpenAI API (optional)
  - model_name: gpt-4o
    litellm_params:
      model: openai/gpt-4o
      api_key: os.environ/OPENAI_API_KEY

  - model_name: gpt-4o-mini
    litellm_params:
      model: openai/gpt-4o-mini
      api_key: os.environ/OPENAI_API_KEY

litellm_settings:
  # Enable cost tracking
  success_callback: ["langfuse"]
  failure_callback: ["langfuse"]

  # Langfuse integration
  langfuse_public_key: os.environ/LANGFUSE_PUBLIC_KEY
  langfuse_secret: os.environ/LANGFUSE_SECRET_KEY
  langfuse_host: os.environ/LANGFUSE_HOST

general_settings:
  # Master key for API authentication
  master_key: os.environ/LITELLM_MASTER_KEY

  # Success callback to notify OpenSpawn API of token usage
  # The x-litellm-secret header authenticates the callback
  # OPENSPAWN_API_URL should include the base URL (e.g., http://localhost:3000 or https://api.openspawn.io)
  success_callback:
    - type: webhook
      url: ${OPENSPAWN_API_URL}/credits/litellm-callback
      headers:
        x-litellm-secret: os.environ/LITELLM_CALLBACK_SECRET
